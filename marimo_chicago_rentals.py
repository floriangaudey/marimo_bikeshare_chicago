# td_bixi_marimo.py
# ============================================================
# TD Marimo ‚Äî Analyse des donn√©es Bixi avec DuckDB
# M1 MIAGE UT Capitole ‚Äî Antoine Giraud
# ============================================================

import marimo

__generated_with = "0.19.6"
app = marimo.App(app_title="1√®re explo DuckDB")


@app.cell(hide_code=True)
def intro(mo):
    mo.md(r"""
    # TD ‚Äî Analyse des stations **divvy** üö≤ @Chicago

    Ce TD vous guide dans l‚Äôexploration de donn√©es r√©elles :
    - Locations journali√®res (.csv -> .parquet)

    Vous utiliserez **DuckDB** et son extension **spatial**.

    üëâ Certaines cellules contiennent des `TODO` √† compl√©ter. üß™
    """)
    return


@app.cell
def imports():
    import marimo as mo
    import duckdb

    # Create a DuckDB connection
    conn = duckdb.connect("explo_chicago.db")
    # on va travailler avec des coordonn√©es
    conn.sql("INSTALL spatial; LOAD spatial;")
    return conn, mo


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ## 1. T√©l√©chargement des "rentals" d'une ann√©e

    Les op√©rateurs de **v√©lo en libre** (bikeshare) d'Am√©rique du Nord mettent √† disposition fr√©quement :
    - le **GBFS** : offre de service temps r√©el des stations (.json)
    - l'**historique** des **locations de v√©lo** ou "rentals" (.csv.zip)

    Nous vous invitons pour ce TP de choisir par groupe de 2 une ann√©e de rentals pour la ville de Chicago. Leur marque de bikeshare s'appelle divvy (√† l'instar de bixi pour Montr√©al)

    Exemple de recherche sur google : [chicago bike rentals opendata](https://www.google.com/search?q=chicago+bike+rentals+opendata) fait bien remonter en 1er r√©sultat la page [divvybikes.com/system-data](https://divvybikes.com/system-data)
    ![screen_google_search_divvy_data](public/screen_google_search_divvy_data.png)

    RDV l√† bas pour y t√©l√©charger les fichiers de votre ann√©e :)

    Nous vous invitons
    - √† les ranger dans le dossier `data/rentals_divvy/annee=yyyy/`
    - √† les d√©zipper vous m√™me, DuckDB ne sait pas lire les .csv.zip !

    Dans un premier temps, vous pouvez v√©rifier si vos sources de donn√©es sont bien pr√©sentes dans le dossier :
    """)
    return


@app.cell
def _(conn, mo):
    _df = mo.sql(
        f"""
        SELECT
            filename,
            (size/1024/1024)::int AS size_mb,
        FROM read_text('data/**')
        """,
        engine=conn
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ## 2. D√©couverte du sch√©ma des donn√©es

    Dans un premier temps, v√©rifiez que vous voyez l'ensemble de vos donn√©es issues de vos sources :
    """)
    return


@app.cell
def _(conn, mo):
    _df = mo.sql(
        f"""
        -- regardons le contenu d'un fichiers
        from 'data/annee=2025/202501-divvy-tripdata.csv'
        """,
        engine=conn
    )
    return


@app.cell
def _(mo):
    mo.md(r"""
    Suite √† la premi√®re analyse de l'ensemble des donn√©es, quelles sont les colonnes qui peuvent √™tre exploit√©es en tant qu'axe d'analyse ?
    """)
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ## 3. Premi√®re r√©duction des donn√©es

    A partir des 12 fichiers, repr√©sentant l'activit√© des locations de v√©los pour chaque mois sur un an, vous allez cr√©er la premi√®re table avec l'ensemble des donn√©es de lann√©e que vous avec choisi.
    """)
    return


@app.cell
def _(conn, mo):
    fact_rentals = mo.sql(
        f"""
        -- pr√©paration fact_rentals
        create or replace table fact_rentals as
        select
            annee,
            DATE_TRUNC('month', started_at) as dt_mois,
            start_station_id,
            end_station_id,
            member_casual,
            DATE_TRUNC('minute', started_at) as started_at,
            DATE_DIFF('second', started_at, ended_at) duration,
        from 'data/annee=2025/*.csv';

        -- affichons les donn√©es
        from fact_rentals;
        """,
        engine=conn
    )
    return (fact_rentals,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    Utilisez la fonction Summarize pour √©valuez le contenu de chaque colonnes :
    """)
    return


@app.cell
def _(conn, fact_rentals, mo):
    _df = mo.sql(
        f"""
        summarize (from fact_rentals where dt_mois = '2025-01-01')
        """,
        engine=conn
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    Suite √† l'analyse des colonnes, vous pouvez cr√©er la premi√®re table de dimension :
    """)
    return


@app.cell
def _(conn, mo):
    dim_station = mo.sql(
        f"""
        -- pr√©paration dim_station
        create or replace table dim_station as
        select
            annee,
            start_station_id as station_id,
            any_value(start_station_name) as nom,
            count(distinct start_station_name) as nb_uq_nom,
            count(1) nb_rentals,
            count(distinct CONCAT_WS('||', start_lng, start_lat)) nb_uq_coords,
            any_value(ST_Point(
                (start_lng)::DOUBLE,
                (start_lat)::DOUBLE
            )) AS station_geom,
            ST_AsGeoJSON(station_geom) AS geom_json,
        from 'data/annee=2025/*.csv'
        group by all;

        -- affichons les donn√©es
        from dim_station;
        """,
        engine=conn
    )
    return (dim_station,)


@app.cell
def _(conn, dim_station, fact_rentals, mo):
    _df = mo.sql(
        f"""
        copy dim_station to 'data/dim_station.parquet';
        copy fact_rentals to 'data/fact_rentals.parquet';
        """,
        engine=conn
    )
    return


@app.cell
def _(conn, mo):
    _df = mo.sql(
        f"""
        copy (
            from 'data/annee=2025/*.csv'
        ) to 'data/raw_rentals_2025.parquet';
        """,
        engine=conn
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ## 4. Cas pratique :

    Vous avez agr√©g√© vos donn√©es dans une table de dimension et une table de Fait (correspondant au layer Silver).
    Vous avez remarqu√© que la taille du parquet et le nombre de donn√©es a diminu√©.

    D√©sormais, vous allez proposer plusieurs cas d'usage suite √† l'exploration des donn√©s que vous allez effectuer sur les donn√©es de Chicago (Correspondant au layer Gold).

    L'attendu est le suivant :
    - Proposer une agr√©gation des donn√©es issues de la table de Fait et de la table de dimension.
    - Expliquer la d√©marche de votre table Gold en ad√©quation avec l'√©tude des locations de v√©los dans Chicago.

    Lorsque votre r√©duction de dimension est termin√©e, vous ex√©cutez le script ci-dessous pour envoyer votre fichier parquet sur un bucket.

    NB : N'oubliez de changer la bonne ann√©e pour √™tre au bon endroit
    """)
    return


@app.cell
def _(conn, mo):
    _df = mo.sql(
        f"""
        copy (from 'data/station_daily_recap.parquet')
        to 's3://bucket-m1-miage-tout-pour-le-collectif/divvy/rentals/annee=2025/station_recap.parquet'
        """,
        engine=conn
    )
    return


if __name__ == "__main__":
    app.run()
